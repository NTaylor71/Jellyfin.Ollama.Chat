# ğŸ¬ Universal Media Ingestion Framework
*Think of it as a Smart Media Butler for Your Digital Library*

## ğŸŒŸ What Is This Project?

Imagine you have a massive digital library with movies, TV shows, books, music, podcasts, and more. Now imagine having a brilliant AI-powered butler who can:
- ğŸ§  **Understand** what each item is about
- ğŸ” **Research** additional information from the internet
- ğŸ“ **Enhance** each item with rich metadata
- ğŸ¯ **Organize** everything intelligently
- ğŸš€ **Search** through it all at lightning speed

That's exactly what this Universal Media Ingestion Framework does! It's like having a team of specialized AI assistants working together to make your media collection incredibly smart and searchable.

## ğŸ­ The Restaurant Kitchen Allegory

Picture this framework as a **world-class restaurant kitchen** where your media items are the ingredients that get transformed into gourmet dishes:

```mermaid
graph TB
    subgraph "ğŸ½ï¸ Universal Media Restaurant"
        A[ğŸ“¦ Raw Media Items<br/>*Fresh Ingredients*] --> B[ğŸ‘¨â€ğŸ³ Head Chef<br/>*Ingestion Manager*]
        B --> C[ğŸ“‹ Recipe Book<br/>*YAML Configurations*]
        
        subgraph "ğŸ”¥ Cooking Stations"
            D[ğŸ§  AI Station<br/>*LLM Service*]
            E[ğŸ” Research Station<br/>*Web Search*] 
            F[ğŸ“Š Analysis Station<br/>*NLP Services*]
            G[ğŸ·ï¸ Tagging Station<br/>*Keyword Extraction*]
        end
        
        C --> D
        C --> E
        C --> F
        C --> G
        
        D --> H[ğŸ¯ Quality Control<br/>*Result Merging*]
        E --> H
        F --> H
        G --> H
        
        H --> I[ğŸ“š Elegant Presentation<br/>*Enhanced Media*]
    end
```

## ğŸ—ï¸ System Architecture: The Smart City Allegory

Think of our system as a **modern smart city** where different districts specialize in different tasks:

```mermaid
graph TB
    subgraph "ğŸ™ï¸ Universal Media City"
        subgraph "ğŸ›ï¸ City Hall District"
            API[ğŸ›ï¸ City Hall<br/>*Main API*]
            IM[ğŸ‘‘ Mayor<br/>*Ingestion Manager*]
        end
        
        subgraph "ğŸ­ Industrial District"
            WS[ğŸ­ Processing Plant<br/>*Worker Service*]
            RM[âš¡ Power Grid<br/>*Resource Manager*]
            QM[ğŸš› Logistics<br/>*Queue Manager*]
        end
        
        subgraph "ğŸ§  AI Research District"
            LLM[ğŸ§  Think Tank<br/>*LLM Service*]
            NLP[ğŸ“Š Analytics Lab<br/>*NLP Services*]
            WEB[ğŸ” Investigation Bureau<br/>*Web Search*]
        end
        
        subgraph "ğŸ“š Knowledge District"
            MONGO[ğŸ“š Great Library<br/>*MongoDB*]
            REDIS[âš¡ Message Center<br/>*Redis Cache*]
            FAISS[ğŸ” Search Index<br/>*Vector Database*]
        end
        
        API --> IM
        IM --> WS
        WS --> RM
        WS --> QM
        QM --> LLM
        QM --> NLP
        QM --> WEB
        LLM --> MONGO
        NLP --> MONGO
        WEB --> MONGO
        WS --> REDIS
        MONGO --> FAISS
    end
```

## ğŸ¯ The Ingestion Process: From Raw to Refined

### ğŸŒŠ The Data Flow River

```mermaid
flowchart TD
    START[ğŸ¬ Raw Media Item] --> VALIDATE{ğŸ“‹ Valid Format?}
    VALIDATE -->|âœ… Yes| ANALYZE[ğŸ” Analyze Fields]
    VALIDATE -->|âŒ No| ERROR[âŒ Reject Item]
    
    ANALYZE --> YAML[ğŸ“– Load YAML Recipe]
    YAML --> PLUGINS[ğŸ­ Select Enhancement Plugins]
    
    subgraph "ğŸ­ The Enhancement Theater"
        PLUGINS --> P1[ğŸ§  LLM Keyword Plugin<br/>*The Wordsmith*]
        PLUGINS --> P2[ğŸ” Web Search Plugin<br/>*The Detective*]
        PLUGINS --> P3[ğŸ“Š NLP Analysis Plugin<br/>*The Analyst*]
        PLUGINS --> P4[ğŸ·ï¸ Concept Expansion Plugin<br/>*The Librarian*]
        PLUGINS --> P5[â° Temporal Plugin<br/>*The Historian*]
        
        P1 --> MERGE[ğŸ¯ Merge Results<br/>*The Director*]
        P2 --> MERGE
        P3 --> MERGE
        P4 --> MERGE
        P5 --> MERGE
    end
    
    MERGE --> STORE[ğŸ“š Store in MongoDB]
    STORE --> INDEX[ğŸ” Update Search Index]
    INDEX --> DONE[âœ¨ Enhanced Media Item]
```

## ğŸ­ Meet the Cast: Our AI Character System

### ğŸ§  The Plugins: Your Specialized AI Assistants

Think of plugins as **skilled artisans** in our media workshop:

#### ğŸ¨ The Wordsmith (LLM Keyword Plugin)
```mermaid
graph LR
    A[ğŸ“ Raw Text] --> B[ğŸ§  LLM Wordsmith]
    B --> C[ğŸ’ Refined Keywords]
    B --> D[ğŸ¯ Smart Summaries]
    B --> E[ğŸ·ï¸ Intelligent Tags]
```
*"I read your movie description and craft beautiful, meaningful keywords that capture its essence."*

#### ğŸ” The Detective (Web Search Plugin)
```mermaid
graph LR
    A[ğŸ¬ Movie Title] --> B[ğŸ” Web Detective]
    B --> C[â­ Reviews & Ratings]
    B --> D[ğŸ† Awards & Recognition]
    B --> E[ğŸ“ˆ Box Office Data]
```
*"I investigate the internet to find the latest information about your media items."*

#### ğŸ“Š The Analyst (NLP Services)
```mermaid
graph LR
    A[ğŸ“– Text Content] --> B[ğŸ“Š NLP Analyst]
    B --> C[ğŸ˜Š Sentiment Analysis]
    B --> D[ğŸ‘¥ Named Entities]
    B --> E[â° Temporal Information]
```
*"I analyze the language to understand emotions, people, places, and time references."*

#### ğŸ·ï¸ The Librarian (ConceptNet Plugin)
```mermaid
graph LR
    A[ğŸ¯ Keywords] --> B[ğŸ·ï¸ Concept Librarian]
    B --> C[ğŸ”— Related Concepts]
    B --> D[ğŸ“š Knowledge Graph]
    B --> E[ğŸ¨ Semantic Expansion]
```
*"I connect your content to a vast web of human knowledge and understanding."*

### ğŸ¢ The Services: Your Specialized Departments

Think of services as **expert departments** in our media corporation:

#### ğŸ§  The Think Tank (LLM Service)
*"We're the creative minds who understand language and generate insights."*

#### ğŸ” The Research Department (Web Search Service)
*"We're the investigators who find the latest information from across the internet."*

#### ğŸ“Š The Analytics Division (NLP Services)
*"We're the scientists who analyze text and extract meaningful patterns."*

#### ğŸ·ï¸ The Knowledge Management Team (ConceptNet Service)
*"We're the librarians who connect everything to human knowledge."*

### ğŸ­ The Providers: Your Skilled Craftspeople

Providers are like **master craftspeople** who actually do the detailed work:

```mermaid
graph TB
    subgraph "ğŸ­ The Craftsmanship Workshop"
        A[ğŸ§  LLM Provider<br/>*Master Linguist*] --> B[ğŸ“ Text Generation]
        A --> C[ğŸ¯ Keyword Extraction]
        A --> D[ğŸ“‹ Summarization]
        
        E[ğŸ” Web Provider<br/>*Master Researcher*] --> F[ğŸŒ Search Execution]
        E --> G[ğŸ“Š Data Collection]
        E --> H[ğŸ¯ Result Filtering]
        
        I[ğŸ“Š NLP Provider<br/>*Master Analyst*] --> J[ğŸ·ï¸ Entity Recognition]
        I --> K[ğŸ˜Š Sentiment Analysis]
        I --> L[â° Temporal Extraction]
    end
```

## ğŸ“– YAML: The Recipe Books

YAML configurations are like **detailed recipe books** that tell our AI chefs exactly how to prepare each type of media:

### ğŸ¬ Movie Recipe Example
```yaml
# ğŸ¬ Movie Enhancement Recipe
media_type: "movie"
description: "Recipe for making movies incredibly searchable and smart"

# ğŸ¥˜ Ingredients (Fields to enhance)
fields:
  title:
    weight: 3.0        # ğŸ”¥ High importance
    plugins: ["llm_keyword", "web_search"]
  
  overview:
    weight: 2.5        # ğŸŒŸ Very important
    plugins: ["llm_keyword", "nlp_analysis", "concept_expansion"]
  
  genres:
    weight: 2.0        # ğŸ“Š Important
    plugins: ["concept_expansion"]

# ğŸ‘¨â€ğŸ³ Cooking Instructions (Plugin configuration)
plugins:
  llm_keyword:
    temperature: 0.7   # ğŸ¯ Creativity level
    max_keywords: 15   # ğŸ·ï¸ Number of keywords
  
  web_search:
    max_results: 10    # ğŸ” Research depth
    sources: ["imdb", "tmdb", "metacritic"]
```

### ğŸµ Music Recipe Example
```yaml
# ğŸµ Music Enhancement Recipe
media_type: "music"
description: "Recipe for making music collections sing with intelligence"

fields:
  artist:
    weight: 3.0
    plugins: ["web_search", "concept_expansion"]
  
  album:
    weight: 2.5
    plugins: ["llm_keyword", "web_search"]
  
  lyrics:
    weight: 2.0
    plugins: ["nlp_analysis", "sentiment_analysis"]
```

## ğŸ’» System Requirements

### ğŸ·ï¸ **TL;DR Quick Reference**

| **System Tier** | **CPU** | **RAM** | **Storage** | **Use Case** |
|------------------|---------|---------|-------------|--------------|
| **Minimum** | 4 cores | 8GB | 50GB SSD | Small collections, basic enrichment |
| **Recommended** | 8 cores | 16GB | 100GB SSD | Medium collections, full features |
| **High-Performance** | 16+ cores | 32GB+ | 200GB+ SSD | Large collections, maximum quality |

### ğŸ¯ **Detailed Requirements by Deployment Tier**

#### ğŸ¥‰ **Minimum Requirements** (Budget/Testing)
*"Getting your feet wet with a small media collection"*

| Component | Specification | Explanation |
|-----------|---------------|-------------|
| **CPU** | 4 cores, 8 threads | Core services need 2-4 threads each |
| **RAM** | 8GB total | Base services (2GB) + MongoDB (1GB) + models (3GB) + OS (2GB) |
| **Storage** | 50GB SSD | Docker images (10GB) + models (15GB) + data (25GB) |
| **GPU** | None required | CPU-only LLM models available |

**Model Optimizations for Minimum Systems:**
- Ollama: Use `llama3.2:1b` (1.3GB) instead of `llama3.2:3b` (2.0GB)
- SpaCy: Use `en_core_web_sm` (15MB) instead of `en_core_web_lg` (750MB)
- Disable GPU-intensive services in docker-compose

#### ğŸ¥ˆ **Recommended Requirements** (Balanced Performance)
*"Sweet spot for most users with medium collections"*

| Component | Specification | Explanation |
|-----------|---------------|-------------|
| **CPU** | 8 cores, 16 threads | Parallel processing of multiple media items |
| **RAM** | 16GB total | All services (8GB) + larger models (4GB) + caching (4GB) |
| **Storage** | 100GB SSD | Full model set (30GB) + growing media database (70GB) |
| **GPU** | 4GB VRAM (optional) | Accelerates LLM processing, 3-5x speed improvement |

**Optimal Model Configuration:**
- Ollama: `llama3.2:3b` for good quality/speed balance
- SpaCy: `en_core_web_md` (50MB) for good accuracy with word vectors
- All enrichment services enabled

#### ğŸ¥‡ **High-Performance Requirements** (Maximum Quality)
*"Professional setups and large media libraries"*

| Component | Specification | Explanation |
|-----------|---------------|-------------|
| **CPU** | 16+ cores, 32+ threads | Concurrent processing of many items |
| **RAM** | 32GB+ total | Large models in memory + extensive caching |
| **Storage** | 200GB+ NVMe SSD | Full model collection + large database + logs |
| **GPU** | 8GB+ VRAM | Large LLM models, batch processing |

**Maximum Quality Configuration:**
- Ollama: `llama3.1:8b` or larger models for best quality
- SpaCy: `en_core_web_lg` (750MB) for maximum accuracy
- All services with increased resource limits

### ğŸ”§ **Why Each Component Matters**

#### ğŸ§  **CPU Requirements Explained**
- **15 Microservices**: Each service needs 1-2 CPU threads minimum
- **AI Processing**: NLP analysis, keyword extraction, and text processing are CPU-intensive
- **Parallel Processing**: Multiple media items can be processed simultaneously
- **Background Tasks**: Queue management, health checks, and monitoring

#### ğŸ **Memory Requirements Breakdown**
```
Base Docker Services:          ~2GB
â”œâ”€â”€ MongoDB + Redis:           ~1GB
â”œâ”€â”€ Monitoring (Prometheus):   ~512MB
â””â”€â”€ Base containers:           ~512MB

AI Models in Memory:           ~3-15GB
â”œâ”€â”€ Ollama LLM:               ~1-8GB (model dependent)
â”œâ”€â”€ SpaCy NLP:                ~15MB-750MB (model dependent)
â”œâ”€â”€ Other AI models:          ~1-2GB
â””â”€â”€ Model caching:            ~1-4GB

Application Runtime:           ~2-8GB
â”œâ”€â”€ Service processes:        ~2GB
â”œâ”€â”€ Request processing:       ~1-2GB
â”œâ”€â”€ Result caching:          ~1-2GB
â””â”€â”€ OS overhead:             ~2GB
```

#### ğŸ’¾ **Storage Requirements Detail**
```
Docker Images:                 ~10GB
â”œâ”€â”€ Base Python images:       ~3GB
â”œâ”€â”€ Service images:           ~4GB
â””â”€â”€ Infrastructure images:    ~3GB

AI Models:                     ~5-30GB
â”œâ”€â”€ Ollama models:            ~1-20GB
â”œâ”€â”€ SpaCy models:             ~15MB-750MB per language
â”œâ”€â”€ NLTK data:                ~500MB
â””â”€â”€ Gensim models:            ~1-5GB

Application Data:              ~Growing
â”œâ”€â”€ MongoDB collections:      ~Varies by usage
â”œâ”€â”€ Logs and metrics:         ~1-5GB
â”œâ”€â”€ Cache storage:            ~2-10GB
â””â”€â”€ Backup space:             ~20% of total
```

### âš¡ **Performance vs Resource Trade-offs**

#### ğŸ›ï¸ **Model Size Impact on Performance**

| Model Choice | Size | Quality | Speed | Memory | Best For |
|--------------|------|---------|--------|---------|----------|
| `llama3.2:1b` | 1.3GB | Good | Fast | Low | Testing, small collections |
| `llama3.2:3b` | 2.0GB | Very Good | Medium | Medium | General use, balanced |
| `llama3.1:8b` | 4.7GB | Excellent | Slower | High | Large collections, quality-focused |

#### ğŸ”„ **Service Scaling Options**

**Resource-Constrained Setup:**
```yaml
# Disable optional services
profiles: ["core"]  # Skip search, monitoring
deploy:
  resources:
    limits:
      memory: 512M    # Limit per service
      cpus: 0.5       # Limit CPU usage
```

**High-Performance Setup:**
```yaml
# Scale up resources
deploy:
  resources:
    limits:
      memory: 4G      # More memory per service
      cpus: 2.0       # More CPU allocation
    reservations:
      devices:
        - capabilities: ["gpu"]  # GPU acceleration
```

### ğŸ¥ **Hardware Compatibility Notes**

#### ğŸ–¥ï¸ **CPU Compatibility**
- **Minimum**: Intel Core i5 4th gen / AMD Ryzen 3000 series
- **Recommended**: Intel Core i7 8th gen / AMD Ryzen 5000 series
- **Architecture**: x86_64 required (ARM64 experimental)

#### ğŸ® **GPU Support**
- **NVIDIA**: GTX 1060 6GB or newer (CUDA support)
- **AMD**: Limited support via ROCm (experimental)
- **Apple Silicon**: CPU-only mode (Metal acceleration coming)
- **Setup**: Requires NVIDIA Container Toolkit

#### ğŸ’¿ **Storage Recommendations**
- **SSD Strongly Recommended**: 5-10x faster model loading
- **Network Storage**: Possible but may impact performance
- **Backup Strategy**: Regular MongoDB dumps recommended

### ğŸš€ **Getting Started with Your Hardware**

#### ğŸ“ **Step 1: Assess Your System**
```bash
# Check your system specs
lscpu | grep -E "CPU|Thread|Core"
free -h
df -h
nvidia-smi  # If you have NVIDIA GPU
```

#### âš™ï¸ **Step 2: Choose Your Configuration**
- **8GB RAM or less**: Use minimum configuration
- **16GB RAM**: Standard recommended setup
- **32GB+ RAM**: High-performance configuration

#### ğŸ¯ **Step 3: Optimize for Your Hardware**
- Edit `config/hardware/default.yaml` to match your specs
- Adjust `config/models/ollama_models.yaml` for model selection
- Modify docker-compose resource limits if needed

## ğŸš€ Getting Started: Your First Media Enhancement

### 1. ğŸ—ï¸ Set Up Your Workshop
```bash
# Clone the magical workshop
git clone <repository-url>
cd universal-media-ingestion

# Set up your Python environment
./dev_setup.sh

# Activate your virtual environment
source .venv/bin/activate

# Start the AI services
docker-compose -f docker-compose.dev.yml up -d
```

### 2. ğŸ¬ Enhance Your First Movie
```python
import requests

# ğŸ“ Raw movie data
movie_data = {
    "title": "The Matrix",
    "year": 1999,
    "overview": "A computer hacker learns about the true nature of reality..."
}

# ğŸš€ Send to enhancement
response = requests.post(
    "http://localhost:8000/api/v1/ingestion/ingest",
    json={
        "media_type": "movie",
        "data": movie_data
    }
)

# âœ¨ Get enhanced result
enhanced_movie = response.json()
print(f"Enhanced with {len(enhanced_movie['keywords'])} keywords!")
```

### 3. ğŸ” Search Your Enhanced Collection
```python
# ğŸ¯ Search for action movies
search_response = requests.get(
    "http://localhost:8000/api/v1/search/query",
    params={
        "q": "cyberpunk action thriller",
        "media_type": "movie"
    }
)

results = search_response.json()
print(f"Found {len(results['items'])} matches!")
```

## ğŸ”§ API Reference: Working Examples

### ğŸ“¡ Main API Endpoints (Port 8000)

#### ğŸ¬ **Ingest Media Items**
```bash
# Ingest a single movie with comprehensive spaCy analysis
curl -X POST "http://localhost:8000/api/v1/ingest/media" \
  -H "Content-Type: application/json" \
  -d '{
    "media_type": "movie",
    "media_items": [{
      "Name": "The Matrix",
      "Overview": "A computer hacker learns about the true nature of reality and joins a rebellion against the machines.",
      "Genres": ["Action", "Sci-Fi"],
      "ProductionYear": 1999
    }],
    "skip_enrichment": false,
    "batch_size": 1
  }'
```

#### ğŸ” **Search Enhanced Media**
```bash
# Search for movies using AI-enhanced metadata
curl -X GET "http://localhost:8000/api/v1/search/movie" \
  -G \
  -d "query=cyberpunk dystopian reality" \
  -d "limit=10" \
  -d "include_metadata=true"
```

#### ğŸ“Š **Get Media Items**
```bash
# Retrieve all movies with enriched data
curl -X GET "http://localhost:8000/api/v1/media/movie" \
  -G \
  -d "limit=5" \
  -d "include_enriched=true"
```

#### âš¡ **Enrich Existing Media**
```bash
# Re-enrich a specific movie with updated plugins
curl -X POST "http://localhost:8000/api/v1/media/movie/enrich" \
  -H "Content-Type: application/json" \
  -d '{
    "item_filter": {"Name": "The Matrix"},
    "plugins": ["spacy_ner", "spacy_linguistic", "llm_keywords"],
    "force_refresh": true
  }'
```

#### ğŸ”¬ **Analyze Text Fields**
```bash
# Analyze a specific text field with spaCy
curl -X POST "http://localhost:8000/api/v1/media/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "This critically acclaimed science fiction film explores themes of reality and consciousness.",
    "analysis_types": ["entities", "linguistic", "patterns"],
    "media_context": "movie"
  }'
```

### ğŸ§  SpaCy Service Endpoints (Port 8007)

#### ğŸ·ï¸ **Named Entity Recognition**
```bash
# Extract people, organizations, locations, and more
curl -X POST "http://localhost:8007/providers/spacy/entities" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Directed by the Wachowskis and starring Keanu Reeves, The Matrix was filmed in Sydney, Australia and won four Academy Awards.",
    "field_name": "overview",
    "options": {
      "model": "en_core_web_md",
      "entity_types": ["PERSON", "ORG", "GPE", "WORK_OF_ART"],
      "confidence_threshold": 0.7,
      "group_by_type": true
    }
  }'
```

#### ğŸ“ **Linguistic Analysis**
```bash
# Analyze sentence structure, POS tags, and readability
curl -X POST "http://localhost:8007/providers/spacy/linguistic" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "In a dystopian future where humanity is unknowingly trapped inside a simulated reality, a computer programmer discovers the truth.",
    "field_name": "plot_analysis",
    "options": {
      "model": "en_core_web_md",
      "extract_pos": true,
      "extract_dependencies": true,
      "analyze_readability": true,
      "extract_adjectives": true
    }
  }'
```

#### ğŸ”— **Text Similarity**
```bash
# Compare similarity between two movie descriptions
curl -X POST "http://localhost:8007/providers/spacy/similarity" \
  -H "Content-Type: application/json" \
  -d '{
    "text1": "A computer hacker discovers the truth about reality.",
    "text2": "A programmer learns about the nature of the Matrix.",
    "options": {
      "model": "en_core_web_md"
    }
  }'
```

#### â° **Temporal Analysis**
```bash
# Extract dates, times, and temporal concepts
curl -X POST "http://localhost:8007/providers/spacy_temporal/expand" \
  -H "Content-Type: application/json" \
  -d '{
    "concept": "Released in 1999, this groundbreaking film from the late 20th century",
    "media_context": "movie",
    "max_concepts": 10,
    "options": {
      "extract_dates": true,
      "normalize_dates": true
    }
  }'
```

### ğŸ”§ Service Health & Management

#### ğŸ¥ **Check Service Health**
```bash
# Main API health
curl -X GET "http://localhost:8000/health"

# SpaCy service health
curl -X GET "http://localhost:8007/health"

# Detailed provider health
curl -X POST "http://localhost:8007/providers/spacy_temporal/health"
```

#### ğŸ“¦ **Model Management**
```bash
# Check model status
curl -X GET "http://localhost:8007/models/status"

# Download specific models
curl -X POST "http://localhost:8007/models/download" \
  -H "Content-Type: application/json" \
  -d '{
    "model_ids": ["english_model_md"],
    "force_download": false
  }'

# Check if models are ready
curl -X GET "http://localhost:8007/models/ready"
```

#### ğŸ“‹ **Service Discovery**
```bash
# List available providers
curl -X GET "http://localhost:8007/providers"

# Get provider metadata
curl -X GET "http://localhost:8007/providers/spacy_temporal/metadata"
```

### ğŸ¯ Advanced Workflow Examples

#### ğŸ¬ **Complete Movie Analysis Pipeline**
```bash
# 1. Ingest with full enrichment
curl -X POST "http://localhost:8000/api/v1/ingest/media" \
  -H "Content-Type: application/json" \
  -d '{
    "media_type": "movie",
    "media_items": [{
      "Name": "Blade Runner 2049",
      "Overview": "A young blade runner discovers a secret that could plunge society into chaos and leads him on a quest to find Rick Deckard.",
      "Genres": ["Sci-Fi", "Thriller"],
      "ProductionYear": 2017,
      "Director": "Denis Villeneuve"
    }]
  }'

# 2. Search for similar content
curl -X GET "http://localhost:8000/api/v1/search/movie" \
  -G \
  -d "query=dystopian future androids" \
  -d "limit=5"

# 3. Get detailed enriched data
curl -X GET "http://localhost:8000/api/v1/media/movie" \
  -G \
  -d "filter_name=Blade Runner 2049" \
  -d "include_enriched=true"
```

#### ğŸ”¬ **Text Analysis Deep Dive**
```bash
# 1. Extract all entities
curl -X POST "http://localhost:8007/providers/spacy/entities" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Christopher Nolan'\''s Inception starring Leonardo DiCaprio explores the architecture of dreams.",
    "options": {"entity_types": "ALL", "confidence_threshold": 0.6}
  }'

# 2. Analyze linguistic complexity
curl -X POST "http://localhost:8007/providers/spacy/linguistic" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "The film'\''s intricate narrative structure challenges conventional storytelling.",
    "options": {"analyze_readability": true, "extract_pos": true}
  }'

# 3. Find domain patterns
curl -X POST "http://localhost:8007/providers/spacy_temporal/expand" \
  -H "Content-Type: application/json" \
  -d '{
    "concept": "This critically acclaimed box office hit won the Academy Award for Best Picture.",
    "options": {"pattern_categories": ["awards", "critical_reception"]}
  }'
```

### ğŸ“Š Response Examples

#### ğŸ·ï¸ **Entity Extraction Response**
```json
{
  "success": true,
  "provider_name": "spacy_ner",
  "execution_time_ms": 45.2,
  "result": {
    "structured_entities": {
      "people": [
        {"text": "Keanu Reeves", "confidence": 0.95, "label": "PERSON"},
        {"text": "Wachowskis", "confidence": 0.89, "label": "PERSON"}
      ],
      "organizations": [
        {"text": "Warner Bros", "confidence": 0.87, "label": "ORG"}
      ],
      "locations": [
        {"text": "Sydney", "confidence": 0.91, "label": "GPE"}
      ]
    },
    "total_entities": 4
  }
}
```

#### ğŸ“ **Linguistic Analysis Response**
```json
{
  "success": true,
  "provider_name": "spacy_linguistic",
  "execution_time_ms": 67.8,
  "result": {
    "pos_analysis": {
      "complexity_indicators": {
        "noun_density": 25.5,
        "adjective_density": 12.3
      }
    },
    "sentence_analysis": {
      "avg_sentence_length": 18.5,
      "complexity_level": "medium"
    },
    "adjective_analysis": {
      "sentiment_indicators": {
        "positive_count": 3,
        "sentiment_score": 2
      }
    }
  }
}
```

## ğŸ¯ Understanding the Two-Layer Architecture

### ğŸ—ï¸ **API Layer vs Service Layer: When to Use Which**

Our system provides **two distinct interaction layers** designed for different use cases. Understanding when to use each is crucial for effective integration.

### ğŸ­ **High-Level API Layer** (`/api/v1/media/{media_type}/enrich`)
*The Orchestra Conductor*

This is the **user-facing, business logic layer** that orchestrates complete media enrichment workflows.

#### **What it does:**
- Orchestrates **multiple plugins** in sequence
- Applies **YAML configuration** rules automatically
- Manages **field mapping** and data transformation
- Handles **result merging** from multiple sources
- Stores results in **MongoDB** with full persistence
- Applies **confidence scoring** and **intelligent caching**

#### **Example: Complete Movie Enhancement**
```bash
# Enrich a complete movie with multiple AI services
curl -X POST "http://localhost:8000/api/v1/media/movie/enrich" \
  -H "Content-Type: application/json" \
  -d '{
    "item_filter": {"Name": "The Matrix"},
    "plugins": ["spacy_ner", "llm_keywords", "conceptnet_keywords"],
    "force_refresh": true
  }'
```

#### **What happens internally:**
1. ğŸ“– Loads movie from MongoDB
2. âš™ï¸ Reads `movie.yaml` configuration
3. ğŸ”„ Executes spaCy NER â†’ LLM Keywords â†’ ConceptNet in sequence
4. ğŸ¯ Merges results using configured strategies
5. ğŸ’¾ Stores enhanced data back to MongoDB
6. ğŸ“¤ Returns complete enriched movie object

---

### ğŸ”§ **Low-Level Service Layer** (`/providers/spacy/*`)
*The Individual Musicians*

This is the **raw NLP processing layer** that provides atomic, focused operations.

#### **What it does:**
- Performs **single, focused tasks**
- Processes **raw text** without business context
- Returns **structured NLP data** immediately
- No database interaction or persistence
- No configuration orchestration

#### **Example: Raw Text Analysis**
```bash
# Extract entities from any text
curl -X POST "http://localhost:8007/providers/spacy/entities" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Christopher Nolan directed Inception starring Leonardo DiCaprio",
    "options": {"entity_types": ["PERSON", "WORK_OF_ART"]}
  }'
```

#### **What happens internally:**
1. ğŸ¤– Loads spaCy model
2. âš¡ Processes text with NER
3. ğŸ“Š Returns structured entity data
4. âœ¨ No storage, no orchestration - pure processing

---

## ğŸª **The Restaurant Analogy**

### ğŸ½ï¸ **API Layer = Full Restaurant Experience**
- You order "the movie enhancement special"
- Kitchen coordinates multiple chefs (plugins)
- Follows the recipe book (YAML configuration)  
- Serves a complete, plated meal (enriched media object)
- Meal is recorded in your dining history (MongoDB)

### ğŸ‘¨â€ğŸ³ **Service Layer = Individual Chef Stations**
- You go directly to the sushi chef (spaCy service)
- Request specific preparation (entity extraction)
- Get raw, unplated ingredients (structured NLP data)
- No coordination with other chefs
- No meal recording

---

## ğŸ¯ **When to Use Each Layer**

### ğŸ¬ **Use API Layer** (`/api/v1/media/...`) When:

âœ… **Complete Media Processing**
```bash
# Process entire movies with full enrichment pipeline
curl -X POST "/api/v1/ingest/media" -d '{
  "media_type": "movie", 
  "media_items": [{"Name": "Blade Runner", "Overview": "..."}]
}'
```

âœ… **Configuration-Driven Workflows**
- Want YAML rules applied automatically
- Need multiple plugins orchestrated together  
- Require result merging and confidence scoring

âœ… **Production Media Management**
- Adding movies to your media library
- Re-enriching existing content
- Building media search indexes

âœ… **Business Logic Operations**
- Database persistence required
- Complex field mapping needed
- Multi-step processing workflows

---

### ğŸ§  **Use Service Layer** (`/providers/spacy/...`) When:

âœ… **Raw NLP Analysis**
```bash
# Analyze any text snippet
curl -X POST "/providers/spacy/entities" -d '{
  "text": "Any text you want analyzed"
}'
```

âœ… **Building Custom Applications**
- Creating your own enrichment logic
- Bypassing the standard media workflow
- Experimenting with NLP capabilities

âœ… **Research and Development**
- Testing spaCy model performance
- Comparing different analysis approaches
- Prototyping new features

âœ… **Integration with External Systems**
- Your own database schema
- Custom data processing pipelines
- Real-time text analysis

---

## ğŸ”„ **Real-World Usage Patterns**

### ğŸ“š **Pattern 1: Complete Media Library Management**
```bash
# 1. Ingest movies with full enrichment (API Layer)
curl -X POST "/api/v1/ingest/media" \
  -d '{"media_type": "movie", "media_items": [...]}'

# 2. Search enhanced collection (API Layer)
curl -X GET "/api/v1/search/movie?query=cyberpunk"

# 3. Re-enrich with new plugins (API Layer)
curl -X POST "/api/v1/media/movie/enrich" \
  -d '{"plugins": ["spacy_linguistic"]}'
```

### ğŸ”¬ **Pattern 2: Custom Text Analysis Tool**
```bash
# 1. Extract entities (Service Layer)
curl -X POST "/providers/spacy/entities" \
  -d '{"text": "Custom text analysis"}'

# 2. Analyze linguistic features (Service Layer)
curl -X POST "/providers/spacy/linguistic" \
  -d '{"text": "Same text", "options": {"analyze_readability": true}}'

# 3. Process results in your application
# (Your custom logic here)
```

### ğŸ­ **Pattern 3: Hybrid Approach**
```bash
# 1. Use API for standard media (API Layer)
curl -X POST "/api/v1/ingest/media" -d '{...}'

# 2. Use services for custom fields (Service Layer)
curl -X POST "/providers/spacy/entities" \
  -d '{"text": "Custom metadata field"}'

# 3. Combine results in your application
```

---

## ğŸ“Š **Quick Decision Guide**

| **Need to...** | **Use This Layer** |
|----------------|-------------------|
| Manage movies/TV/books? | **API Layer** |
| Analyze any text? | **Service Layer** |
| Build a media app? | **API Layer** |
| Build an NLP tool? | **Service Layer** |
| Want YAML configuration? | **API Layer** |
| Want direct control? | **Service Layer** |
| Store in database? | **API Layer** |
| Process and discard? | **Service Layer** |

The API layer is your **media management system**, while the service layer is your **NLP toolkit**! ğŸ¯

---

## ğŸ—ï¸ Architecture Deep Dive

### ğŸ­ The Plugin System: A Theater Company

```mermaid
graph TB
    subgraph "ğŸ­ The Enhancement Theater"
        DIRECTOR[ğŸ¬ Plugin Manager<br/>*The Director*]
        
        subgraph "ğŸ¨ Performance Stages"
            STAGE1[ğŸ§  LLM Stage<br/>*Creative Writing*]
            STAGE2[ğŸ” Research Stage<br/>*Investigation*]
            STAGE3[ğŸ“Š Analysis Stage<br/>*Data Science*]
            STAGE4[ğŸ·ï¸ Knowledge Stage<br/>*Connections*]
        end
        
        DIRECTOR --> STAGE1
        DIRECTOR --> STAGE2
        DIRECTOR --> STAGE3
        DIRECTOR --> STAGE4
        
        STAGE1 --> FINALE[ğŸ¯ Grand Finale<br/>*Result Merging*]
        STAGE2 --> FINALE
        STAGE3 --> FINALE
        STAGE4 --> FINALE
    end
```

### ğŸ­ The Service Ecosystem: An Industrial Symphony

```mermaid
graph TB
    subgraph "ğŸ­ The Processing Symphony"
        CONDUCTOR[ğŸ¼ Service Orchestrator]
        
        subgraph "ğŸº Brass Section - Core Services"
            API[ğŸº API Service<br/>*The Announcer*]
            WORKER[ğŸº Worker Service<br/>*The Performer*]
            MANAGER[ğŸº Resource Manager<br/>*The Coordinator*]
        end
        
        subgraph "ğŸ» String Section - AI Services"
            LLM[ğŸ» LLM Service<br/>*The Virtuoso*]
            NLP[ğŸ» NLP Service<br/>*The Analyst*]
            SEARCH[ğŸ» Search Service<br/>*The Explorer*]
        end
        
        subgraph "ğŸ¥ Percussion Section - Data Services"
            MONGO[ğŸ¥ MongoDB<br/>*The Keeper*]
            REDIS[ğŸ¥ Redis<br/>*The Messenger*]
            FAISS[ğŸ¥ FAISS<br/>*The Finder*]
        end
        
        CONDUCTOR --> API
        CONDUCTOR --> WORKER
        CONDUCTOR --> MANAGER
        
        API --> LLM
        WORKER --> NLP
        WORKER --> SEARCH
        
        LLM --> MONGO
        NLP --> MONGO
        SEARCH --> MONGO
        
        WORKER --> REDIS
        MONGO --> FAISS
    end
```

## ğŸ¯ Advanced Features

### ğŸ”¥ Queue Processing: The Smart Assembly Line

```mermaid
graph LR
    subgraph "ğŸ­ Smart Assembly Line"
        INPUT[ğŸ“¦ Raw Media] --> QUEUE[ğŸ“‹ Task Queue]
        QUEUE --> CPU[ğŸ’» CPU Workers]
        QUEUE --> GPU[ğŸ® GPU Workers]
        
        CPU --> LIGHT[âš¡ Light Tasks]
        GPU --> HEAVY[ğŸ”¥ Heavy AI Tasks]
        
        LIGHT --> OUTPUT[âœ¨ Enhanced Media]
        HEAVY --> OUTPUT
    end
```

### ğŸŒ Web Search Integration: The Information Highway

```mermaid
graph TB
    subgraph "ğŸŒ Information Superhighway"
        QUERY[ğŸ” Search Query] --> SEARXNG[ğŸš— SearXNG Vehicle]
        SEARXNG --> SOURCES[ğŸª Information Shops]
        
        subgraph "ğŸª Knowledge Marketplace"
            IMDB[ğŸ¬ IMDb Store]
            WIKI[ğŸ“š Wikipedia Library]
            NEWS[ğŸ“° News Stand]
            SOCIAL[ğŸ’¬ Social Media Cafe]
        end
        
        SOURCES --> IMDB
        SOURCES --> WIKI
        SOURCES --> NEWS
        SOURCES --> SOCIAL
        
        IMDB --> RESULTS[ğŸ¯ Collected Information]
        WIKI --> RESULTS
        NEWS --> RESULTS
        SOCIAL --> RESULTS
        
        RESULTS --> LLM[ğŸ§  AI Analysis]
        LLM --> ENHANCED[âœ¨ Enhanced Knowledge]
    end
```

## ğŸ† What Makes This Framework Special?

### ğŸŒŸ Universal Design
- ğŸ¬ **Any Media Type**: Movies, music, books, podcasts, games, comics
- ğŸ”Œ **Any Data Source**: Jellyfin, Plex, JSON files, APIs
- ğŸ§  **Any AI Provider**: OpenAI, Anthropic, local models

### ğŸš€ Performance & Scalability
- âš¡ **Parallel Processing**: Multiple AI workers running simultaneously
- ğŸ¯ **Smart Resource Management**: CPU and GPU tasks scheduled optimally
- ğŸ“Š **Comprehensive Monitoring**: Real-time metrics and health checks

### ğŸ¨ Developer-Friendly
- ğŸ§© **Plugin Architecture**: Easy to extend with new capabilities
- ğŸ“– **Configuration-Driven**: No code changes needed for new media types
- ğŸ”§ **Rich APIs**: Full REST API for all operations

## ğŸ“ Learning Resources

### ğŸ“š For Beginners
1. **Start Here**: Run the setup script and enhance your first movie
2. **Explore**: Look at the YAML configurations in `config/media_types/`
3. **Experiment**: Try different plugins and see how they change results

### ğŸ”¬ For Advanced Users
1. **Custom Plugins**: Create your own enhancement plugins
2. **New Services**: Add new AI services to the ecosystem
3. **Performance Tuning**: Optimize for your specific use case

### ğŸ—ï¸ For Developers
1. **Architecture**: Study the service and plugin patterns
2. **Testing**: Run the comprehensive test suite
3. **Contributing**: Add new features following the established patterns

## ğŸ‰ Success Stories

*"I pointed this at my 10,000 movie collection and it found connections I never knew existed!"* - Happy User

*"The web search integration keeps my metadata fresh and current automatically."* - Media Enthusiast

*"Building custom plugins was surprisingly straightforward with the HTTP-only architecture."* - Developer

---

## ğŸ¤ Contributing

This framework thrives on community contributions! Whether you're:
- ğŸ¨ Adding new enhancement plugins
- ğŸ”§ Improving existing services
- ğŸ“– Enhancing documentation
- ğŸ› Fixing bugs

Your contributions make this universal media framework even more powerful!

---

**ğŸ¬ Ready to transform your media collection into an intelligent, searchable, AI-enhanced library? Let's get started!**